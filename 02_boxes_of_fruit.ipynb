{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Practicum AI Logo image](https://github.com/PracticumAI/practicumai.github.io/blob/main/images/logo/PracticumAI_logo_250x50.png?raw=true) <img src='https://github.com/PracticumAI/deep_learning/blob/main/images/practicumai_deep_learning.png?raw=true' alt='Practicum AI: Deep Learning Foundations icon' align='right' width=50>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Computer Vision Tasks\n",
    "\n",
    "Now that Kevin has a better understanding of how computer vision classification works, he needs to learn more about other computer vision tasks. His manager has asked him to move on from wasps and bees to... fruits and (bounding) boxes! Kevin thankfully has an annotated dataset already, so he can start learning about object detection.\n",
    "\n",
    "As before, the dataset was found on. [Check out the dataset information](https://www.kaggle.com/datasets/lakshaytyagi01/fruit-detection/data)\n",
    "\n",
    "![Image of fruits and bounding boxes from the dataset cover image](notebook_images/fruits_detection_dataset-cover.jpg)\n",
    "\n",
    "This notebook will be a bit different than the previous ones: it doesn't use TensorFlow or Keras. Instead, it uses PyTorch, torchvision and YOLOv8. Whereas TensorFlow and Keras are easier to use for a variety of deep learning tasks (such as image classification), PyTorch is more popular and currently better suited for object detection. YOLOv8 (You Only Look Once, version 8) is a popular object detection model that is known for its speed, accuracy and relative ease of implementation.\n",
    "\n",
    "As we've mentioned before, these tools are rapidly evolving, so it's important to stay up-to-date with the latest versions and best practices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Import the libraries we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This notebook will be used for an Object Detection task that trains a model on the fruits_detection dataset using YOLOv8\n",
    "\n",
    "# Importing the necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import pathlib\n",
    "import requests\n",
    "import zipfile\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml \n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Training on {device}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting the data\n",
    "\n",
    "As we did in Notebook 1, we will have to download the dataset. This time the file is stored as a zip file, so we will need to extract it. \n",
    "\n",
    "You will also notice that instead of loading things to the **data** directory, the data is instead loaded to a new folder called **datasets**. This is a requirement of YOLOv8, which expects the data to be in a specific folder. The setting is *technically* possible to change, but is not something we want to hassle with right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_file(url=\"https://www.dropbox.com/scl/fi/ioupfqya76b7p8m1v1kdc/fruits_detection.zip?rlkey=ofgre83fdxa98p7ity8j9z8ip&st=atv7sz18&dl=1\", filename=\"fruits_detection.zip\"):\n",
    "                        \n",
    "    # Check to see if the datasets folder exists\n",
    "    if not os.path.exists(\"datasets\"):\n",
    "        os.makedirs(\"datasets\")\n",
    "    \n",
    "    # Download the file using requests\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # Create a file object and write the response content in chunks\n",
    "    with open(filename, \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "\n",
    "    # Wait for the file to finish downloading\n",
    "    while not os.path.exists(filename):\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Print a success message\n",
    "    print(f\"Downloaded {filename} successfully.\")\n",
    "\n",
    "def extract_file(filename, data_folder):\n",
    "    # Check if the file is a zip file\n",
    "    if zipfile.is_zipfile(filename):\n",
    "        # Open the zip file\n",
    "        with zipfile.ZipFile(filename, \"r\") as zip_ref:\n",
    "            # Extract all the files to the data folder\n",
    "            zip_ref.extractall(data_folder)\n",
    "            # Print a success message\n",
    "            print(f\"Extracted {filename} to {data_folder} successfully.\")\n",
    "    else:\n",
    "        # Print an error message\n",
    "        print(type(filename))\n",
    "        print(f\"{filename} is not a valid zip file.\")\n",
    "    \n",
    "def manage_data(folder_name='fruits_detection'):\n",
    "    '''Try to find the data for the exercise and return the path'''\n",
    "    \n",
    "    # Check common paths of where the data might be on different systems\n",
    "    likely_paths= [os.path.normpath(f'/blue/practicum-ai/share/data/{folder_name}'),\n",
    "                   os.path.normpath(f'/project/scinet_workshop2/data/{folder_name}'),\n",
    "                   os.path.join('datasets', folder_name),\n",
    "                   os.path.normpath(folder_name)]\n",
    "    \n",
    "    for path in likely_paths:\n",
    "        if os.path.exists(path):\n",
    "            print(f'Found data at {path}.')\n",
    "            return path\n",
    "\n",
    "    answer = input(f'Could not find data in the common locations. Do you know the path? (yes/no): ')\n",
    "\n",
    "    if answer.lower() == 'yes':\n",
    "        path = os.path.join(os.path.normpath(input('Please enter the path to the data folder: ')),folder_name)\n",
    "        if os.path.exists(path):\n",
    "            print(f'Thanks! Found your data at {path}.')\n",
    "            return path\n",
    "        else:\n",
    "            print(f'Sorry, that path does not exist.')\n",
    "    \n",
    "    answer = input('Do you want to download the data? (yes/no): ')\n",
    "\n",
    "    if answer.lower() == 'yes':\n",
    "\n",
    "        ''' Check and see if the downloaded data is inside the .gitignore file, and adds them to the list of files to ignore if not. \n",
    "        This is to prevent the data from being uploaded to the repository, as the files are too large for GitHub.'''\n",
    "        \n",
    "        if os.path.exists('.gitignore'):\n",
    "            with open('.gitignore', 'r') as f:\n",
    "                ignore = f.read().split('\\n')\n",
    "        # If the .gitignore file does not exist, create a new one\n",
    "        elif not os.path.exists('.gitignore'):\n",
    "            with open('.gitignore', 'w') as f:\n",
    "                f.write('')\n",
    "            ignore = []\n",
    "        else:\n",
    "            ignore = []\n",
    "\n",
    "        # Check if the .gz file is in the ignore list\n",
    "        if 'fruits_detection.zip' not in ignore:\n",
    "            ignore.append('fruits_detection.zip')\n",
    "            \n",
    "        # Check if the data/ folder is in the ignore list\n",
    "        if 'datasets/' not in ignore:\n",
    "            ignore.append('datasets/')\n",
    "\n",
    "        # Write the updated ignore list back to the .gitignore file\n",
    "        with open('.gitignore', 'w') as f:\n",
    "            f.write('\\n'.join(ignore))\n",
    "\n",
    "        print(\"Updated .gitignore file.\")\n",
    "        print('Downloading data, this may take a minute.')\n",
    "        download_file()\n",
    "        print('Data downloaded, unpacking')\n",
    "        extract_file(\"fruits_detection.zip\", \"datasets\")\n",
    "        print('Data downloaded and unpacked. Now available at datasets/fruits_detection.')\n",
    "        return os.path.normpath('datasets/fruits_detection')   \n",
    "\n",
    "    print('Sorry, I cannot find the data. Please download it manually from https://www.kaggle.com/datasets/lakshaytyagi01/fruit-detection/ and unpack it to the datasets folder.')      \n",
    "\n",
    "\n",
    "data_path = manage_data() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore the dataset\n",
    "\n",
    "We will take a look at the dataset to see what it contains. We will also look at the annotations file, which contains the bounding box information for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign the path to the dataset\n",
    "data_dir = r\"datasets/fruits_detection\"\n",
    "\n",
    "# Make a histogram of the number of images in each class\n",
    "def explore_data(data_dir, show_picture=True, show_annotation=True, show_detection=True, show_hist=True):\n",
    "\n",
    "    # Define the class names\n",
    "    class_names = ['Apple', 'Banana', 'Grape', 'Orange', 'Pineapple', 'Watermelon']\n",
    "    \n",
    "    # Examine some sample images\n",
    "    if show_picture:\n",
    "        # Get valid image folders \n",
    "        image_folders = [f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))] \n",
    "\n",
    "        sample_images = []\n",
    "        for i in range(5):\n",
    "            folder = random.choice(image_folders) \n",
    "            img_path = os.path.join(data_dir, folder, 'images', random.choice(os.listdir(os.path.join(data_dir, folder, 'images'))))\n",
    "            sample_images.append(img_path)\n",
    "\n",
    "        # Plot the sample images\n",
    "        fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
    "        for i, img_path in enumerate(sample_images):\n",
    "            img = Image.open(img_path)\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    # Examine the first five annotation files\n",
    "    if show_annotation:\n",
    "        annotation_files = []\n",
    "        for folder in os.listdir(data_dir):\n",
    "            if os.path.isdir(os.path.join(data_dir, folder)):\n",
    "                annotation_folder = os.path.join(data_dir, folder, 'labels')\n",
    "                if os.path.exists(annotation_folder):\n",
    "                    for file in os.listdir(annotation_folder):\n",
    "                        annotation_files.append(os.path.join(annotation_folder, file))\n",
    "        for file in annotation_files[:5]:\n",
    "            with open(file, 'r') as f:\n",
    "                print(f\"File: {file}\")\n",
    "                for i, line in enumerate(f):\n",
    "                    if i > 4:\n",
    "                        break\n",
    "                    print(f\"  {line.strip()}\")\n",
    "\n",
    "    # Plot five random images with their associated, labeled bounding boxes\n",
    "    if show_detection:\n",
    "        # Get valid image folders \n",
    "        image_folders = [f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))] \n",
    "\n",
    "        sample_images = []\n",
    "        for i in range(5):\n",
    "            folder = random.choice(image_folders) \n",
    "            img_path = os.path.join(data_dir, folder, 'images', random.choice(os.listdir(os.path.join(data_dir, folder, 'images'))))\n",
    "            annotation_path = os.path.join(data_dir, folder, 'labels', os.path.basename(img_path).replace('.jpg', '.txt'))\n",
    "            sample_images.append((img_path, annotation_path))\n",
    "\n",
    "        # Plot the sample images\n",
    "        fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
    "        for i, (img_path, annotation_path) in enumerate(sample_images):\n",
    "            img = Image.open(img_path)\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].axis('off')\n",
    "            with open(annotation_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    class_id, x, y, w, h = map(float, line.strip().split())\n",
    "                    x, y, w, h = x * img.width, y * img.height, w * img.width, h * img.height\n",
    "                    rect = plt.Rectangle((x - w / 2, y - h / 2), w, h, fill=False, color='red', linewidth=2)\n",
    "                    axes[i].add_patch(rect)\n",
    "                    # Add class name above the bounding box\n",
    "                    axes[i].text(x - w / 2, y - h / 2, class_names[int(class_id)], color='red')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    # Make a histogram of the number of images in each class\n",
    "    if show_hist:\n",
    "        def get_class_counts(folder_path):  # Change from data_dir to folder_path\n",
    "            class_counts = {}\n",
    "            labels_path = os.path.join(folder_path, 'labels')  # Add labels path\n",
    "            for filename in os.listdir(labels_path):  # Update listdir\n",
    "                with open(os.path.join(labels_path, filename), 'r') as f:\n",
    "                    for line in f:\n",
    "                        class_id = int(line.split(' ')[0])  # Assuming labels are in YOLO format\n",
    "                        class_counts[class_id] = class_counts.get(class_id, 0) + 1\n",
    "            return class_counts\n",
    "\n",
    "        train_counts = get_class_counts(os.path.join(data_dir, 'train'))  # Add os.path.join\n",
    "        val_counts = get_class_counts(os.path.join(data_dir, 'valid'))\n",
    "        test_counts = get_class_counts(os.path.join(data_dir, 'test'))\n",
    "        num_classes = len(class_names)\n",
    "\n",
    "        data_counts = {\n",
    "            'train': pd.Series(train_counts),\n",
    "            'val': pd.Series(val_counts),\n",
    "            'test': pd.Series(test_counts)\n",
    "        }\n",
    "        df = pd.DataFrame(data_counts)\n",
    "\n",
    "        df.plot.bar(figsize=(10, 6))\n",
    "        plt.xlabel('Class Name')\n",
    "        plt.xticks(np.arange(num_classes), class_names)\n",
    "        plt.ylabel('Number of Images')\n",
    "        plt.title('Distribution of Images per Class')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "explore_data(data_dir, show_picture=True, show_annotation=True, show_detection=True, show_hist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot to unpack here! First, depending on the images sampled, we can see that the images are of different sizes and have different numbers of fruits. Other things to note:\n",
    "- Some of the images don't really contain fruits...\n",
    "- The file names are the same as the image names, but with a .txt extension.\n",
    "- The annotations file contains the class ID of the fruit (0 corresponds to 'Apple', etc.), and the bounding box coordinates. \n",
    "- The bounding box coordinates are in the format (x_min, y_min, x_max, y_max).\n",
    "- The bounding box coordinates are normalized, meaning that they are scaled to be between 0 and 1. This is a common practice in object detection tasks.\n",
    "- The bounding boxes in some of the images are not very accurate. This is a common problem in object detection tasks.\n",
    "- The dataset is very imbalanced, with a lot more oranges than other fruits.\n",
    "\n",
    "## 4. Create the YAML file\n",
    "YAML stands for \"YAML Ain't Markup Language\" and is a human-readable data serialization format. A YAML file is used to define the dataset configuration for training a YOLOv8 model. YAML configuration files are popular in deep learning because they are easier for humans to read and write, with the goal being to increase transparency and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a YAML file for the YOLOv8 model configuration\n",
    "\n",
    "def create_yaml(data_dir, class_names, yaml_file='fruits_detection_data.yaml'):\n",
    "    # Creates a YOLOv8 data.yaml file.\n",
    "    \n",
    "    yaml_dict = {\n",
    "        # 'path': data_dir,  # Path to your dataset\n",
    "        'train': data_dir + '/train/images',  # Relative path to training images\n",
    "        'val': data_dir + '/valid/images',    # Relative path to validation images\n",
    "        'test': data_dir + '/test/images',    # Relative path to testing images\n",
    "\n",
    "        'num_classes': len(class_names),   # Number of classes\n",
    "        'names': class_names      # List of class names\n",
    "    }\n",
    "\n",
    "    with open(yaml_file, 'w') as outfile:\n",
    "        yaml.dump(yaml_dict, outfile, default_flow_style=False)\n",
    "\n",
    "    print(f'YAML file created: {yaml_file}')\n",
    "\n",
    "data_dir = 'fruits_detection'\n",
    "class_names = ['Apple', 'Banana', 'Grape', 'Orange', 'Pineapple', 'Watermelon']\n",
    "\n",
    "create_yaml(data_dir, class_names) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create and fit the model\n",
    "\n",
    "We will create a YOLOv8 model and fit it to the data. YOLOv8 has a lot of hyperparameters that can be tuned, but we will use the default values for now. For more information on the it's hyperparameters, [check out it's documentation](https://docs.ultralytics.com/modes/train/).\n",
    "\n",
    "Another neat feature of YOLOv8 is that by default it provides several evaluation metrics, such as the loss, precision, recall, and F1 score. This is very useful for monitoring the model's performance during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make the YOLOv8 model\n",
    "model = YOLO('yolov8n.yaml')\n",
    "results = model.train(data='fruits_detection_data.yaml', imgsz=640, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the model on a test image\n",
    "img = 'datasets/fruits_detection/test/images/Apple_1.jpg'\n",
    "results = model(img)\n",
    "results.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
